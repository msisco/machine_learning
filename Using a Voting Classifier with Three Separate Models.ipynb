{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the digits dataset because it is relatively small, so it will\n",
    "be fast to fit and estimate a model. I will use three different classifiers on their own and compare the results to see how well they do against the others. Then I will use a Voting Classifier to see if combining the three into a hard or soft vote will work better. The three estimators are Linear Regression, Gaussian Naive Bayes and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following section of loading and preparing the digits dataset is taken from \n",
    "# http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 3 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# pylab.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "X_train = data[:n_samples / 2]\n",
    "y_train = digits.target[:n_samples / 2]\n",
    "X_test = data[n_samples / 2:]\n",
    "y_test = digits.target[n_samples / 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrclass = LogisticRegression( solver = \"lbfgs\")\n",
    "lrclass.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = digits.target[n_samples / 2:]\n",
    "predicted_lr = lrclass.predict(data[n_samples / 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gausClass = GaussianNB()\n",
    "gausClass.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_gc = gausClass.predict(data[n_samples / 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randForestClass = RandomForestClassifier(max_depth=5,n_estimators=100)\n",
    "randForestClass.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_rfc = randForestClass.predict(data[n_samples / 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97        88\n",
      "          1       0.88      0.88      0.88        91\n",
      "          2       0.99      0.97      0.98        86\n",
      "          3       0.99      0.82      0.90        91\n",
      "          4       0.99      0.95      0.97        92\n",
      "          5       0.83      0.91      0.87        91\n",
      "          6       0.95      0.99      0.97        91\n",
      "          7       0.98      0.89      0.93        89\n",
      "          8       0.89      0.90      0.89        88\n",
      "          9       0.82      0.96      0.88        92\n",
      "\n",
      "avg / total       0.93      0.92      0.92       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[85  0  0  0  1  1  1  0  0  0]\n",
      " [ 0 80  0  1  0  0  0  0  4  6]\n",
      " [ 2  0 83  0  0  0  0  0  0  1]\n",
      " [ 0  1  0 75  0  6  0  2  5  2]\n",
      " [ 0  2  0  0 87  0  1  0  0  2]\n",
      " [ 0  2  0  0  0 83  2  0  0  4]\n",
      " [ 0  0  1  0  0  0 90  0  0  0]\n",
      " [ 0  1  0  0  0  5  0 79  1  3]\n",
      " [ 0  4  0  0  0  3  1  0 79  1]\n",
      " [ 1  1  0  0  0  2  0  0  0 88]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (lrclass, metrics.classification_report(expected, predicted_lr)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier GaussianNB():\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.95      0.97        88\n",
      "          1       0.81      0.74      0.77        91\n",
      "          2       0.87      0.84      0.85        86\n",
      "          3       0.88      0.79      0.83        91\n",
      "          4       1.00      0.73      0.84        92\n",
      "          5       0.70      0.81      0.76        91\n",
      "          6       0.96      0.99      0.97        91\n",
      "          7       0.65      0.81      0.72        89\n",
      "          8       0.61      0.76      0.68        88\n",
      "          9       0.77      0.66      0.71        92\n",
      "\n",
      "avg / total       0.82      0.81      0.81       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[84  0  0  0  0  2  0  0  1  1]\n",
      " [ 0 67  2  0  0  0  0  2 13  7]\n",
      " [ 0  8 72  0  0  1  2  0  3  0]\n",
      " [ 0  2  2 72  0  2  0  2  9  2]\n",
      " [ 1  0  0  0 67  0  0 22  1  1]\n",
      " [ 0  2  0  4  0 74  1  3  2  5]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  2  0  0 12  0 72  2  1]\n",
      " [ 0  2  5  0  0  9  0  4 67  1]\n",
      " [ 1  1  0  6  0  5  1  6 11 61]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (gausClass, metrics.classification_report(expected, predicted_gc)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_gc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97        88\n",
      "          1       0.91      0.81      0.86        91\n",
      "          2       0.96      0.87      0.91        86\n",
      "          3       0.83      0.85      0.84        91\n",
      "          4       0.94      0.92      0.93        92\n",
      "          5       0.87      0.88      0.87        91\n",
      "          6       0.98      0.99      0.98        91\n",
      "          7       0.91      1.00      0.95        89\n",
      "          8       0.93      0.84      0.88        88\n",
      "          9       0.79      0.88      0.83        92\n",
      "\n",
      "avg / total       0.91      0.90      0.90       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 74  1  3  2  1  0  0  0 10]\n",
      " [ 1  0 75  6  0  0  0  0  0  4]\n",
      " [ 1  2  1 77  0  1  0  4  5  0]\n",
      " [ 3  0  0  0 85  2  0  1  0  1]\n",
      " [ 0  1  0  1  1 80  2  0  0  6]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 89  0  0]\n",
      " [ 0  3  1  2  1  5  0  1 74  1]\n",
      " [ 0  0  0  4  0  3  0  3  1 81]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (randForestClass, metrics.classification_report(expected, predicted_rfc)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_rfc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok the reports are in and it shows that for the digits dataset the Linear Regression model has the greatest overall accuracy, but the other two were better in certain cases. Even though Gausian Naives Bayes had poorer overall if was best in 0,4 classifiers. Random Forests was best in 1,5,8,9. So with three good models lets let's hoping the Voting Classifier can be better combining all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first selection will be to use a hard voting scheme. That is each of the three cast a vote and majority wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), ('rf', RandomFores...ob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)), ('gnb', GaussianNB())],\n",
      "         voting='hard', weights=None):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97        88\n",
      "          1       0.87      0.84      0.85        91\n",
      "          2       0.96      0.93      0.95        86\n",
      "          3       0.93      0.86      0.89        91\n",
      "          4       0.98      0.95      0.96        92\n",
      "          5       0.86      0.92      0.89        91\n",
      "          6       0.98      0.99      0.98        91\n",
      "          7       0.93      0.96      0.94        89\n",
      "          8       0.88      0.88      0.88        88\n",
      "          9       0.86      0.90      0.88        92\n",
      "\n",
      "avg / total       0.92      0.92      0.92       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 76  2  2  0  0  0  0  4  7]\n",
      " [ 2  4 80  0  0  0  0  0  0  0]\n",
      " [ 1  1  0 78  0  3  0  3  5  0]\n",
      " [ 1  1  0  0 87  1  0  1  0  1]\n",
      " [ 0  0  0  0  0 84  2  0  0  5]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  1  1  0  0  1  0 85  1  0]\n",
      " [ 0  2  0  1  1  6  0  1 77  0]\n",
      " [ 0  1  0  3  0  3  0  1  1 83]]\n"
     ]
    }
   ],
   "source": [
    "vclHardVote = VotingClassifier(estimators=[('lr', lrclass), ('rf', randForestClass), ('gnb', gausClass)], voting='hard')\n",
    "vclHardVote.fit(X_train,y_train)\n",
    "predicted_vclh = vclHardVote.predict(data[n_samples / 2:])\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (vclHardVote, metrics.classification_report(expected, predicted_vclh)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_vclh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok looks like Hard Vote brought the strongest one down with two weaker ones. Let's see how soft voting and works compared to hard voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), ('rf', RandomFores...ob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)), ('gnb', GaussianNB())],\n",
      "         voting='soft', weights=None):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98        88\n",
      "          1       0.90      0.82      0.86        91\n",
      "          2       0.92      0.97      0.94        86\n",
      "          3       0.96      0.85      0.90        91\n",
      "          4       1.00      0.92      0.96        92\n",
      "          5       0.89      0.90      0.90        91\n",
      "          6       0.98      0.99      0.98        91\n",
      "          7       0.84      0.96      0.89        89\n",
      "          8       0.80      0.85      0.82        88\n",
      "          9       0.85      0.86      0.85        92\n",
      "\n",
      "avg / total       0.91      0.91      0.91       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  0  0  0  0  1  0]\n",
      " [ 0 75  2  1  0  0  0  0  6  7]\n",
      " [ 0  3 83  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 77  0  2  0  3  7  1]\n",
      " [ 1  0  0  0 85  0  0  5  1  0]\n",
      " [ 0  1  0  1  0 82  2  0  0  5]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  1  2  0  0  1  0 85  0  0]\n",
      " [ 0  2  2  0  0  5  0  3 75  1]\n",
      " [ 1  0  0  1  0  2  0  5  4 79]]\n"
     ]
    }
   ],
   "source": [
    "vclSoftVote = VotingClassifier(estimators=[('lr', lrclass), ('rf', randForestClass), ('gnb', gausClass)], voting='soft')\n",
    "vclSoftVote.fit(X_train,y_train)\n",
    "predicted_vcls = vclSoftVote.predict(data[n_samples / 2:])\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (vclSoftVote, metrics.classification_report(expected, predicted_vcls)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_vcls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok So soft voting wasn't quite as good either.\n",
    "Up next is weighted voting. best used if the classifiers perform better than others, so is the case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), ('rf', RandomFores...ob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)), ('gnb', GaussianNB())],\n",
      "         voting='soft', weights=[5, 8, 1]):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97        88\n",
      "          1       0.92      0.87      0.89        91\n",
      "          2       1.00      0.98      0.99        86\n",
      "          3       0.99      0.84      0.90        91\n",
      "          4       0.99      0.93      0.96        92\n",
      "          5       0.86      0.93      0.89        91\n",
      "          6       0.96      1.00      0.98        91\n",
      "          7       0.98      0.93      0.95        89\n",
      "          8       0.87      0.91      0.89        88\n",
      "          9       0.84      0.95      0.89        92\n",
      "\n",
      "avg / total       0.94      0.93      0.93       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 79  0  1  0  0  0  0  4  7]\n",
      " [ 2  0 84  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 76  0  6  0  2  5  1]\n",
      " [ 1  1  0  0 86  0  1  0  1  2]\n",
      " [ 0  0  0  0  0 85  2  0  0  4]\n",
      " [ 0  0  0  0  0  0 91  0  0  0]\n",
      " [ 0  1  0  0  0  3  0 83  1  1]\n",
      " [ 0  3  0  0  0  3  1  0 80  1]\n",
      " [ 1  1  0  0  0  2  0  0  1 87]]\n"
     ]
    }
   ],
   "source": [
    "vclSoftVoteWeight = VotingClassifier(estimators=[('lr', lrclass), ('rf', randForestClass), ('gnb', gausClass)], voting='soft',weights=[5,8,1])\n",
    "vclSoftVoteWeight.fit(X_train,y_train)\n",
    "predicted_vclsw = vclSoftVoteWeight.predict(data[n_samples / 2:])\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (vclSoftVoteWeight, metrics.classification_report(expected, predicted_vclsw)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_vclsw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurrah! With enough tweaking I could get the Voting Classifier to beat the best of the three classifiers. It turns out that weighting the Random Tree Classifier higher than the others brought the score up the highest even though the Linear Regression performs better than it head to head. Since the Gaussian Naive Bayes was doing poorly in comparison I did try leaving it out, but that made it worse. Even though it only gets a weight of 1 it still made a difference. Final Weighting to bring the score up above 93%\n",
    "Random Forest Classifier 8\n",
    "Linear Regression 5\n",
    "Gaussian Naive Bayes 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
